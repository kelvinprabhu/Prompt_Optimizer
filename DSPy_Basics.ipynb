{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c20ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "api_key = getpass.getpass(\"Enter your GROQ API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e57a20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class GroqLM(dspy.LM):\n",
    "    def __init__(self, model=\"llama-3.3-70b-versatile\", **kwargs):\n",
    "        super().__init__(model=model, **kwargs)\n",
    "        self.model_name = model\n",
    "        self.client = ChatGroq(model=model,\n",
    "                               api_key=api_key,)\n",
    "\n",
    "    def __call__(self, prompt=None, messages=None, **kwargs):\n",
    "        # Handle both prompt and messages format\n",
    "        if messages:\n",
    "            # Convert DSPy messages to LangChain format\n",
    "            lc_messages = []\n",
    "            for msg in messages:\n",
    "                if msg.get(\"role\") == \"system\":\n",
    "                    lc_messages.append(SystemMessage(content=msg[\"content\"]))\n",
    "                elif msg.get(\"role\") == \"user\":\n",
    "                    lc_messages.append(HumanMessage(content=msg[\"content\"]))\n",
    "            response = self.client.invoke(lc_messages)\n",
    "        else:\n",
    "            # Handle simple prompt format\n",
    "            response = self.client.invoke([HumanMessage(content=prompt)])\n",
    "        \n",
    "        return [response.content]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96f7aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Army and the Chinese Army are two of the largest and most powerful military forces in the world. Here's a comparison of the two:\n",
      "\n",
      "**Personnel:**\n",
      "- Indian Army: approximately 1.4 million active personnel\n",
      "- Chinese Army (People's Liberation Army): approximately 2.2 million active personnel\n",
      "\n",
      "**Tanks:**\n",
      "- Indian Army: around 4,065 tanks (including Arjun, T-90, and T-72)\n",
      "- Chinese Army: around 7,150 tanks (including Type 99, Type 96, and Type 90)\n",
      "\n",
      "**Aircraft:**\n",
      "- Indian Army: around 700 aircraft (including helicopters and transport planes)\n",
      "- Chinese Army: around 2,755 aircraft (including helicopters, transport planes, and fighter jets)\n",
      "\n",
      "**Naval Power:**\n",
      "- Indian Navy: around 295 ships (including submarines, destroyers, and aircraft carriers)\n",
      "- Chinese Navy: around 710 ships (including submarines, destroyers, and aircraft carriers)\n",
      "\n",
      "**Nuclear Capabilities:**\n",
      "- India: estimated 150-200 nuclear warheads\n",
      "- China: estimated 290-320 nuclear warheads\n",
      "\n",
      "**Defense Budget:**\n",
      "- India: around $67 billion (2022)\n",
      "- China: around $230 billion (2022)\n",
      "\n",
      "It's essential to note that military strength is not solely determined by numbers. Other factors like technology, training, strategy, and geography also play crucial roles. The Indian Army has been modernizing and strengthening its capabilities in recent years, while the Chinese Army has been rapidly expanding and upgrading its military.\n",
      "\n",
      "In the event of a conflict, the outcome would depend on various factors, including the specific location, the tactics employed, and the international response. However, based on sheer numbers and resources, the Chinese Army appears to have an advantage over the Indian Army.\n"
     ]
    }
   ],
   "source": [
    "# Configure DSPy to use the GroqLM\n",
    "lm = GroqLM()\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "predict = dspy.Predict(\"question -> answer\")\n",
    "out = predict(question=\"indian army vs chinese army \")\n",
    "print(out.answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92240091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90255845",
   "metadata": {},
   "source": [
    "MODEL INIT WITH DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063431e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "lm = dspy.LM(\"gemini/gemini-2.5-flash\", api_key=GEMINI_API_KEY)\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c56bd6",
   "metadata": {},
   "source": [
    "1 . MATH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70ec6f59",
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/llms/openai/openai.py:745\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[39m\n\u001b[32m    744\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m745\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    746\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m OpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/llms/openai/openai.py:647\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[39m\n\u001b[32m    644\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    645\u001b[39m         status_code=\u001b[32m422\u001b[39m, message=\u001b[33m\"\u001b[39m\u001b[33mmax retries must be an int\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m openai_client: OpenAI = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_openai_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_async\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/llms/openai/openai.py:395\u001b[39m, in \u001b[36mOpenAIChatCompletion._get_openai_client\u001b[39m\u001b[34m(self, is_async, api_key, api_base, api_version, timeout, max_retries, organization, client, shared_session)\u001b[39m\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     _new_client = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhttp_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOpenAIChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_sync_http_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m        \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;66;03m## SAVE CACHE KEY\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/main.py:2164\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   2158\u001b[39m     logging.post_call(\n\u001b[32m   2159\u001b[39m         \u001b[38;5;28minput\u001b[39m=messages,\n\u001b[32m   2160\u001b[39m         api_key=api_key,\n\u001b[32m   2161\u001b[39m         original_response=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m   2162\u001b[39m         additional_args={\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: headers},\n\u001b[32m   2163\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2164\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m optional_params.get(\u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2167\u001b[39m     \u001b[38;5;66;03m## LOGGING\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/main.py:2136\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   2135\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2136\u001b[39m         response = \u001b[43mopenai_chat_completions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2137\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2138\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2139\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2140\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2141\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2142\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2143\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2144\u001b[39m \u001b[43m            \u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m=\u001b[49m\u001b[43macompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2145\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlogging_obj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2146\u001b[39m \u001b[43m            \u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptional_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2147\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlitellm_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2148\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogger_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2149\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m   2150\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_prompt_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2151\u001b[39m \u001b[43m            \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass AsyncOpenAI, OpenAI client\u001b[39;49;00m\n\u001b[32m   2152\u001b[39m \u001b[43m            \u001b[49m\u001b[43morganization\u001b[49m\u001b[43m=\u001b[49m\u001b[43morganization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2153\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2154\u001b[39m \u001b[43m            \u001b[49m\u001b[43mshared_session\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshared_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2155\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2157\u001b[39m     \u001b[38;5;66;03m## LOGGING - log the original exception returned\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/llms/openai/openai.py:756\u001b[39m, in \u001b[36mOpenAIChatCompletion.completion\u001b[39m\u001b[34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[39m\n\u001b[32m    755\u001b[39m     error_headers = \u001b[38;5;28mgetattr\u001b[39m(error_response, \u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m756\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    757\u001b[39m     status_code=status_code,\n\u001b[32m    758\u001b[39m     message=error_text,\n\u001b[32m    759\u001b[39m     headers=error_headers,\n\u001b[32m    760\u001b[39m     body=error_body,\n\u001b[32m    761\u001b[39m )\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m math = dspy.ChainOfThought(\u001b[33m\"\u001b[39m\u001b[33mquestion -> answer: float\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mindia vs pakistan who will win?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/utils/callback.py:234\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[32m    237\u001b[39m call_id = uuid.uuid4().hex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/primitives/program.py:22\u001b[39m, in \u001b[36mModule.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/predict/chain_of_thought.py:20\u001b[39m, in \u001b[36mChainOfThought.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/utils/callback.py:234\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[32m    237\u001b[39m call_id = uuid.uuid4().hex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/predict/predict.py:67\u001b[39m, in \u001b[36mPredict.__call__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;129m@with_callbacks\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/predict/predict.py:97\u001b[39m, in \u001b[36mPredict.forward\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdspy\u001b[39;00m\n\u001b[32m     96\u001b[39m adapter = dspy.settings.adapter \u001b[38;5;129;01mor\u001b[39;00m dspy.ChatAdapter()\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m completions = \u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdemos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m pred = Prediction.from_completions(completions, signature=signature)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33m_trace\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m dspy.settings.trace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/adapters/base.py:23\u001b[39m, in \u001b[36mAdapter.__call__\u001b[39m\u001b[34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[39m\n\u001b[32m     20\u001b[39m inputs_ = \u001b[38;5;28mself\u001b[39m.format(signature, demos, inputs)\n\u001b[32m     21\u001b[39m inputs_ = \u001b[38;5;28mdict\u001b[39m(prompt=inputs_) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs_, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(messages=inputs_)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m outputs = \u001b[43mlm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m values = []\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/utils/callback.py:234\u001b[39m, in \u001b[36mwith_callbacks.<locals>.wrapper\u001b[39m\u001b[34m(instance, *args, **kwargs)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;66;03m# If no callbacks are provided, just call the function\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callbacks:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Generate call ID as the unique identifier for the call, this is useful for instrumentation.\u001b[39;00m\n\u001b[32m    237\u001b[39m call_id = uuid.uuid4().hex\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/clients/lm.py:114\u001b[39m, in \u001b[36mLM.__call__\u001b[39m\u001b[34m(self, prompt, messages, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_in_memory:\n\u001b[32m    112\u001b[39m     completion = cached_litellm_completion \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cached_litellm_text_completion\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     response = \u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    119\u001b[39m     completion = litellm_completion \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_type == \u001b[33m\"\u001b[39m\u001b[33mchat\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m litellm_text_completion\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/clients/lm.py:314\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(request, *args, **kwargs)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;66;03m# If the cache key cannot be computed (e.g. because it contains a value that cannot\u001b[39;00m\n\u001b[32m    312\u001b[39m     \u001b[38;5;66;03m# be converted to JSON), bypass the cache and call the target function directly\u001b[39;00m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(request, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/cachetools/_cached.py:173\u001b[39m, in \u001b[36m_locked.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# key not found\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m v = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m lock:\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    176\u001b[39m         \u001b[38;5;66;03m# in case of a race, prefer the item already in the cache\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/clients/lm.py:304\u001b[39m, in \u001b[36mrequest_cache.<locals>.decorator.<locals>.func_cached\u001b[39m\u001b[34m(key, request, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;129m@cached\u001b[39m(\n\u001b[32m    296\u001b[39m     \u001b[38;5;66;03m# NB: cachetools doesn't support maxsize=None; it recommends using float(\"inf\") instead\u001b[39;00m\n\u001b[32m    297\u001b[39m     cache=LRUCache(maxsize=maxsize \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33minf\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m )\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunc_cached\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/clients/lm.py:323\u001b[39m, in \u001b[36mcached_litellm_completion\u001b[39m\u001b[34m(request, num_retries)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;129m@request_cache\u001b[39m(maxsize=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_litellm_completion\u001b[39m(request: Dict[\u001b[38;5;28mstr\u001b[39m, Any], num_retries: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno-cache\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mno-store\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/dspy/clients/lm.py:341\u001b[39m, in \u001b[36mlitellm_completion\u001b[39m\u001b[34m(request, num_retries, cache)\u001b[39m\n\u001b[32m    339\u001b[39m stream = dspy.settings.send_stream\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlitellm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mretry_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;66;03m# The stream is already opened, and will be closed by the caller.\u001b[39;00m\n\u001b[32m    348\u001b[39m stream = cast(MemoryObjectSendStream, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/utils.py:1382\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_obj:\n\u001b[32m   1379\u001b[39m     logging_obj.failure_handler(\n\u001b[32m   1380\u001b[39m         e, traceback_exception, start_time, end_time\n\u001b[32m   1381\u001b[39m     )  \u001b[38;5;66;03m# DO NOT MAKE THREADED - router retry fallback relies on this!\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/utils.py:1251\u001b[39m, in \u001b[36mclient.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1249\u001b[39m         print_verbose(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError while checking max token limit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1250\u001b[39m \u001b[38;5;66;03m# MODEL CALL\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m result = \u001b[43moriginal_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m end_time = datetime.datetime.now()\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streaming_request(\n\u001b[32m   1254\u001b[39m     kwargs=kwargs,\n\u001b[32m   1255\u001b[39m     call_type=call_type,\n\u001b[32m   1256\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/main.py:3842\u001b[39m, in \u001b[36mcompletion\u001b[39m\u001b[34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, verbosity, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[39m\n\u001b[32m   3839\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[32m   3840\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   3841\u001b[39m     \u001b[38;5;66;03m## Map to OpenAI Exception\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3842\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mexception_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3843\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3844\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_llm_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3845\u001b[39m \u001b[43m        \u001b[49m\u001b[43moriginal_exception\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3846\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:2328\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m exception_mapping_worked:\n\u001b[32m   2327\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(e, \u001b[33m\"\u001b[39m\u001b[33mlitellm_response_headers\u001b[39m\u001b[33m\"\u001b[39m, litellm_response_headers)\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m   2329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2330\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m error_type \u001b[38;5;129;01min\u001b[39;00m litellm.LITELLM_EXCEPTION_TYPES:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/genai-dev/lib/python3.14/site-packages/litellm/litellm_core_utils/exception_mapping_utils.py:449\u001b[39m, in \u001b[36mexception_type\u001b[39m\u001b[34m(model, original_exception, custom_llm_provider, completion_kwargs, extra_kwargs)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    445\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    446\u001b[39m     \u001b[38;5;129;01min\u001b[39;00m error_str\n\u001b[32m    447\u001b[39m ):\n\u001b[32m    448\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m AuthenticationError(\n\u001b[32m    450\u001b[39m         message=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAuthenticationError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception_provider\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    451\u001b[39m         llm_provider=custom_llm_provider,\n\u001b[32m    452\u001b[39m         model=model,\n\u001b[32m    453\u001b[39m         response=\u001b[38;5;28mgetattr\u001b[39m(original_exception, \u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    454\u001b[39m         litellm_debug_info=extra_information,\n\u001b[32m    455\u001b[39m     )\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mMistral API raised a streaming error\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error_str:\n\u001b[32m    457\u001b[39m     exception_mapping_worked = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mAuthenticationError\u001b[39m: litellm.AuthenticationError: AuthenticationError: OpenAIException - The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "math = dspy.ChainOfThought(\"question -> answer: float\")\n",
    "math(question=\"india vs pakistan who will win?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411311d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c4bafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    answer='Dhoni hit the run'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class QA(dspy.Signature):\n",
    "    \"\"\"to given question generate answers in few words\"\"\"\n",
    "    question = dspy.InputField(desc=\"User's Question\")\n",
    "    answer = dspy.OutputField(desc=\"often in few words\")\n",
    "\n",
    "predict = dspy.Predict(QA) #Instead of dspy.predict(\"question --> answer\")\n",
    "prediction = predict(question=\"who hit the final run in cirket wc 2011 \")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de67012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146d3d67",
   "metadata": {},
   "source": [
    "Chain of thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d3d1e92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The 2011 ICC Cricket World Cup was won by India, who defeated Sri Lanka in the final. The final match was played on April 2, 2011, at the Wankhede Stadium in Mumbai, India. To determine who hit the final run, we need to recall the details of that match. India was chasing a target of 275 runs set by Sri Lanka and needed 4 runs off the last 3 balls when Dhoni and Yuvraj Singh were at the crease, but then Dhoni hit a six and finished the game.',\n",
       "    answer='Dhoni'\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_ans = dspy.ChainOfThought(QA)\n",
    "gen_ans(question=\"who hit the final run in cirket wc 2011 \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a12fb25",
   "metadata": {},
   "source": [
    "Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cbee9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='To answer this question, we need to provide the capital of France and the current president of France. The capital of France is a well-known fact, and the president can be determined by looking up the current political leaders.',\n",
       "    answer='Paris, Emmanuel Macron'\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why modules\n",
    "multi_step_question = \"what is the capital of france? who is the president of france? \"\n",
    "gen_ans = dspy.ChainOfThought(QA)\n",
    "gen_ans(question=multi_step_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1efb7236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The question provides information about the capital of France, which is Paris, and the current president of France, who is Emmanuel Macron as of the last update. However, it does not ask a specific question that requires a direct answer. Given the context, it seems the task is to confirm or restate the information provided about France.',\n",
       "    answer='The capital of France is indeed Paris, and as of the last update, the President of France is Emmanuel Macron.'\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DoubleChainOfThought(dspy.Module):\n",
    "    \"\"\"Module to perform double chain of thought reasoning\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.first_thought = dspy.ChainOfThought(\"question -> answer\")\n",
    "        self.second_thought = dspy.ChainOfThought(\"question -> answer\")\n",
    "\n",
    "    def forward(self, input_question):\n",
    "        # First chain of thought\n",
    "        intermediate_answer = self.first_thought(question=input_question)\n",
    "\n",
    "        # Second chain of thought using the intermediate answer\n",
    "        final_answer = self.second_thought(question=intermediate_answer.answer)\n",
    "\n",
    "        return final_answer\n",
    "double_cot = DoubleChainOfThought()\n",
    "double_cot(input_question=multi_step_question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032b8c39",
   "metadata": {},
   "source": [
    "Outputting Typed Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31e5072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning=\"The 2011 Cricket World Cup was won by India, and the key factor in their victory can be attributed to several players. However, one player who stood out and is often credited with playing a crucial role in India's success is Yuvraj Singh. He was the player of the tournament, scoring 362 runs and taking 15 wickets. His all-round performance was instrumental in India's victory, as he scored crucial runs and took important wickets throughout the tournament.\",\n",
       "    answer='Yuvraj Singh was the key factor in the 2011 Cricket World Cup, with a confidence score of 0.9.',\n",
       "    AnswerConfidence='The answer is Yuvraj Singh, with a confidence score of 0.9, indicating a high level of certainty in the response.'\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class AnswerConfidence(BaseModel):\n",
    "    answer: str = Field(..., description=\"The generated answer\")\n",
    "    confidence: float = Field(..., description=\"Confidence score of the answer between 0 and 1\")\n",
    "class QAWithConfidence(dspy.Signature):\n",
    "    \"\"\"to given question generate answers with confidence score\"\"\"\n",
    "    question = dspy.InputField(desc=\"User's Question\")\n",
    "    answer = AnswerConfidence = dspy.OutputField(desc=\"Answer with confidence score\")\n",
    "\n",
    "generate_with_confidence = dspy.ChainOfThought(QAWithConfidence)\n",
    "generate_with_confidence(question = \"who was the key factor in 2011 cirket worldcup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcacd01f",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76713300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    sentiment='positive',\n",
      "    confidence='high'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Classification(dspy.Signature):\n",
    "    \"\"\"Classify the sentiment of a given text\"\"\"\n",
    "    text: str = dspy.InputField(desc=\"Input text to classify\")\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = dspy.OutputField(desc=\"Sentiment classification\")\n",
    "    confidence: str = dspy.OutputField()\n",
    "classify = dspy.Predict(Classification)\n",
    "result = classify(text=\"I love programming!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99b6399e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    sentiment='Positive',\n",
       "    confidence='Medium'\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "class Classify(dspy.Signature):\n",
    "    \"\"\"Classify sentiment of a given sentence.\"\"\"\n",
    "\n",
    "    sentence: str = dspy.InputField()\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"] = dspy.OutputField()\n",
    "    confidence: float = dspy.OutputField()\n",
    "\n",
    "classify = dspy.Predict(Classify)\n",
    "classify(sentence=\"This book was super fun to read, though not the last chapter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d232f5c0",
   "metadata": {},
   "source": [
    "Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "620be5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Announces iPhone 14\n",
      "Product Announcement\n",
      "- {\"name\": \"Apple Inc.\", \"type\": \"Organization\", \"metadata\": {}}\n",
      "- {\"name\": \"iPhone 14\", \"type\": \"Product\", \"metadata\": {\"manufacturer\": \"Apple Inc.\"}}\n",
      "- {\"name\": \"Tim Cook\", \"type\": \"Person\", \"metadata\": {\"title\": \"CEO\", \"organization\": \"Apple Inc.\"}}\n"
     ]
    }
   ],
   "source": [
    "class ExtractInfo(dspy.Signature):\n",
    "    \"\"\"Extract structured information from text.\"\"\"\n",
    "\n",
    "    text: str = dspy.InputField()\n",
    "    title: str = dspy.OutputField()\n",
    "    headings: list[str] = dspy.OutputField()\n",
    "    entities: list[dict[str, str]] = dspy.OutputField(desc=\"a list of entities and their metadata\")\n",
    "\n",
    "module = dspy.Predict(ExtractInfo)\n",
    "\n",
    "text = \"Apple Inc. announced its latest iPhone 14 today.\" \\\n",
    "    \"The CEO, Tim Cook, highlighted its new features in a press release.\"\n",
    "response = module(text=text)\n",
    "\n",
    "print(response.title)\n",
    "print(response.headings)\n",
    "print(response.entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83f6fc",
   "metadata": {},
   "source": [
    "RAG - Retrieval Argmented generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3eadd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "colbertv2_wiki = dspy.ColBERTv2(url=\"http://20.102.90.50:2017/wiki17_abstracts\")\n",
    "dspy.configure(rm=colbertv2_wiki, lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcab00c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver = dspy.Retrieve(k=3)\n",
    "topKpassages = retriver(\"Iphone\")\n",
    "print(topKpassages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8063e73",
   "metadata": {},
   "source": [
    "Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d744c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5635.917455947665\n"
     ]
    }
   ],
   "source": [
    "def evaluate_math(expression: str):\n",
    "    return dspy.PythonInterpreter({ }).execute(expression)\n",
    "\n",
    "\n",
    "react = dspy.ReAct(\"question -> answer: float\", tools=[evaluate_math])\n",
    "\n",
    "pred = react(question=\"What is 9362158 divided by the year of birth of David Gregory of Kinnairdy castle?\")\n",
    "print(pred.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8199cf9",
   "metadata": {},
   "source": [
    "Multi stage pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "133877ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outline(dspy.Signature):\n",
    "    \"\"\"Outline a thorough overview of a topic.\"\"\"\n",
    "\n",
    "    topic: str = dspy.InputField()\n",
    "    title: str = dspy.OutputField()\n",
    "    sections: list[str] = dspy.OutputField()\n",
    "    section_subheadings: dict[str, list[str]] = dspy.OutputField(desc=\"mapping from section headings to subheadings\")\n",
    "\n",
    "class DraftSection(dspy.Signature):\n",
    "    \"\"\"Draft a top-level section of an article.\"\"\"\n",
    "\n",
    "    topic: str = dspy.InputField()\n",
    "    section_heading: str = dspy.InputField()\n",
    "    section_subheadings: list[str] = dspy.InputField()\n",
    "    content: str = dspy.OutputField(desc=\"markdown-formatted section\")\n",
    "\n",
    "class DraftArticle(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.build_outline = dspy.ChainOfThought(Outline)\n",
    "        self.draft_section = dspy.ChainOfThought(DraftSection)\n",
    "\n",
    "    def forward(self, topic):\n",
    "        outline = self.build_outline(topic=topic)\n",
    "        sections = []\n",
    "        \n",
    "        # Handle case where section_subheadings might be a string or dict\n",
    "        if isinstance(outline.section_subheadings, str):\n",
    "            import json\n",
    "            try:\n",
    "                section_subheadings_dict = json.loads(outline.section_subheadings)\n",
    "            except json.JSONDecodeError:\n",
    "                # If parsing fails, create a simple structure\n",
    "                section_subheadings_dict = {outline.sections[i] if isinstance(outline.sections, list) else \"Section\": [] for i in range(len(outline.sections) if isinstance(outline.sections, list) else 1)}\n",
    "        else:\n",
    "            section_subheadings_dict = outline.section_subheadings\n",
    "        \n",
    "        for heading, subheadings in section_subheadings_dict.items():\n",
    "            section, subheadings = f\"## {heading}\", [f\"### {subheading}\" for subheading in subheadings]\n",
    "            section = self.draft_section(topic=outline.title, section_heading=section, section_subheadings=subheadings)\n",
    "            sections.append(section.content)\n",
    "        return dspy.Prediction(title=outline.title, sections=sections)\n",
    "\n",
    "draft_article = DraftArticle()\n",
    "article = draft_article(topic=\"World Cup 2002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79ba2cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    title='2002 FIFA World Cup Overview: Teams, Matches, and Legacy',\n",
       "    sections=['## Section\\nThe 2002 FIFA World Cup was the 17th edition of the FIFA World Cup, held in South Korea and Japan from May 31 to June 30, 2002. A total of 32 teams participated in the tournament, with Brazil winning the championship by defeating Germany 2-0 in the final. The 2002 FIFA World Cup is notable for being the first World Cup to be held in Asia, and it featured a number of memorable matches and moments, including the surprise elimination of defending champions France in the group stage. The legacy of the 2002 FIFA World Cup continues to be felt, with the tournament serving as a catalyst for the growth of football in Asia and leaving a lasting impact on the sport.']\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58127bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (4.4.1)\n",
      "Requirement already satisfied: filelock in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (2.2.6)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (0.35.3)\n",
      "Requirement already satisfied: packaging in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/kelvin/miniconda3/envs/genai-dev/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
